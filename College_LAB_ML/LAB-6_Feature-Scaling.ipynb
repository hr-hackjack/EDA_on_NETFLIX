{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e180e1ca",
   "metadata": {},
   "source": [
    "# TASK - 6: Feature Scaling: Normalization and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8cf7d",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "There are two primary ways for feature scaling which we will cover in the remainder of this article:\n",
    "\n",
    "\n",
    "Rescaling, or min-max normalization: we scale the data into one of two ranges: [0, 1] or[a, b], often [-1, 1].\n",
    "\n",
    "Standardization, or Z-score normalization: we scale the data so that the mean is zero and variance is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76ceab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46def8b4",
   "metadata": {},
   "source": [
    "___\n",
    "##  Rescaling (min-max normalization)\n",
    "\n",
    "Minmax scaler should be the first choice for scaling. For each feature, each value is subtracted by the minimum value of the respective feature and then divide by the range of original maximum and minimum of the same feature. It has a default range between [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1c0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.array([1.0, 12.4, 3.9, 10.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420bc26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.        , 0.25438596, 0.8245614 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ds = (ds - min(ds)) / (max(ds) - min(ds))   # np.min() & np.max() can also be used\n",
    "n_ds  # This yields an array where the lowest value is now 0.0 and the highest is 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef096b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [1.5       ],\n",
       "       [0.38157895],\n",
       "       [1.23684211]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization In given range of x & y.\n",
    "x = 0\n",
    "y = 1.5 \n",
    "ns_ds = x+((ds - min(ds))*(y - x)/(max(ds) - min(ds))) \n",
    "ns_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e4ca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [1.5       ],\n",
       "       [0.38157895],\n",
       "       [1.23684211]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler as mms  # Normalization\n",
    "ds = ds.reshape(-1, 1) # Column\n",
    "scaler = mms(feature_range=(0, 1.5))\n",
    "n_ds = scaler.fit_transform(ds)\n",
    "n_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e4aae",
   "metadata": {},
   "source": [
    "##  Standardization (Z-scale normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57edca6",
   "metadata": {},
   "source": [
    "In Rescaling, we normalized our dataset based on the minimum and maximum values. \n",
    "Mean and standard deviation are however _not standard_, meaning that nither the mean is 0 nor the standard deviation is 1.\n",
    "\n",
    "StandardScaler rescales each column to have 0 mean and 1 Standard Deviation. It standardizes a feature by subtracting the mean and dividing by the standard deviation. If the original distribution is not normally distributed, it may distort the relative space among the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7ebc1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean --->  0.8571428571428571\n",
      "Std. --->  0.6247448458762822\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean ---> \",np.mean(n_ds))\n",
    "print(\"Std. ---> \",np.std(n_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffb4d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.125     ]\n",
      " [0.91666667]\n",
      " [0.        ]\n",
      " [1.5       ]]\n",
      "0.6354166666666665\n",
      "0.6105090942538584\n"
     ]
    }
   ],
   "source": [
    "dtst = np.array([2.4, 6.2, 1.8, 9.0]).reshape(-1, 1)\n",
    "scaler = mms(feature_range=(0, 1.5))\n",
    "n_dtst = scaler.fit_transform(dtst)\n",
    "print(n_dtst)\n",
    "print(np.mean(n_dtst))\n",
    "print(np.std(n_dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "756584e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.37198868, -0.17149859,  1.02899151,  1.02899151,  1.02899151,\n",
       "       -0.17149859, -1.37198868])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = np.array([1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0])\n",
    "st_ds = (ds - np.average(ds)) / (np.std(ds))\n",
    "st_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1b844f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.37198868],\n",
       "       [-0.17149859],\n",
       "       [ 1.02899151],\n",
       "       [ 1.02899151],\n",
       "       [ 1.02899151],\n",
       "       [-0.17149859],\n",
       "       [-1.37198868]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler as stsc\n",
    "ds = np.array([1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0]).reshape(-1, 1)\n",
    "scaler = stsc()\n",
    "st_ds = scaler.fit_transform(ds)\n",
    "st_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0e65816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean --->  0.00000000000000003172065784643304\n",
      "Std. --->  1.0\n"
     ]
    }
   ],
   "source": [
    "#print(\"Mean ---> \",np.mean(st_ds))\n",
    "print(\"Mean ---> \",np.format_float_positional(np.mean(st_ds), trim='-'))\n",
    "print(\"Std. ---> \",np.std(st_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f4f75",
   "metadata": {},
   "source": [
    "We see that the mean is really close to 0 (as 3.17 * 10^{-17}) and that standard deviation is 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
